{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gzip\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import nengo\n",
    "from nengo.utils.ensemble import response_curves\n",
    "import os\n",
    "import imageio\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_database(path='faces.npz'):\n",
    "    images = []\n",
    "    for file in os.listdir(path):\n",
    "        images.append(imageio.imread(os.path.join(path,file), as_gray=True))\n",
    "    mat = np.array(images, dtype=np.uint8)\n",
    "    return mat\n",
    "mat = np.load('faces.npz')['arr_0'].astype(np.float64)\n",
    "def half_resolution(X,rep=2):\n",
    "    for _ in range(rep):\n",
    "        r,c = 2*(X.shape[0]//2), 2*(X.shape[1]//2)\n",
    "        X = 0.25*(X[:r:2, :c:2] + X[1:r:2, 1:c:2] + X[1:r:2, :c:2] + X[:r:2, 1:c:2])\n",
    "    return X\n",
    "images_small = []\n",
    "for i in range(mat.shape[0]):\n",
    "    images_small.append(half_resolution(mat[i], 3))\n",
    "mat = np.array(images_small)\n",
    "X = (2.0 * mat/255.0-1.0)\n",
    "\n",
    "N = mat.shape[0]\n",
    "h = mat.shape[1]\n",
    "w = mat.shape[2]\n",
    "mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(N, w*h)\n",
    "X_zero_mean = X-np.mean(X,axis=0)\n",
    "X_cov = (X_zero_mean.T @ X_zero_mean)/(X.shape[0]-1)\n",
    "D,V = np.linalg.eigh(X_cov)\n",
    "D = D[::-1]\n",
    "V = V.T[::-1,:]\n",
    "V = V / np.linalg.norm(V,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN = int(np.floor(np.sqrt(N)))\n",
    "cmap = cm.get_cmap('gray')\n",
    "fig, axs = plt.subplots(NN, NN, figsize=(5.5, 7))\n",
    "for i in range(NN):\n",
    "    for j in range(NN):\n",
    "        axs[i, j].imshow(V[NN * i + j].reshape(h, w), vmin=-0.125, vmax=0.125, cmap=cmap)\n",
    "        axs[i, j].set_xticks([])\n",
    "        axs[i, j].set_yticks([])\n",
    "fig.tight_layout(w_pad=0.0, h_pad=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.plot(D)\n",
    "plt.xlabel(\"nth eigenface\")\n",
    "plt.ylabel(\"eigenvalue\")\n",
    "plt.subplots_adjust(right=2)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(D)\n",
    "plt.xlim(-1, 60)\n",
    "plt.xlabel(\"nth eigenface\")\n",
    "plt.ylabel(\"eigenvalue\")\n",
    "plt.title(\"zoomed in\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Since the magnitude of the eigenvalues to the corresponding eigenvectors indicates how important the eigenface is, we can take the first x eigenfaces where the magnitude of its eigenvalue is relatively high. Looking at the zoomed in graph on the right, we see that selecting only the first 20 eigenfaces or even the first 15 will suffice for our Encoders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genRandomLinearCombinations(faceList, n):\n",
    "    from random import sample\n",
    "    combinations = []\n",
    "    for _ in range(n):\n",
    "        numFaces = np.random.randint(1,25)\n",
    "        coefficients = np.random.randint(-10,10,numFaces)\n",
    "        indcs = np.random.randint(0, len(faceList)-1, numFaces)\n",
    "        faces = [faceList[i] for i in indcs]\n",
    "        combinations.append(sum([c*f for c,f in zip(coefficients,faces)]))\n",
    "    return np.array(combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numEigenfaces = 15\n",
    "encoders = V[:numEigenfaces]\n",
    "#numCombs = (h*w)-numEigenfaces\n",
    "#combs = genRandomLinearCombinations(encoders, (h*w)-numEigenfaces)\n",
    "#E = np.concatenate((encoders, combs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# want to keep the same ensemble and see how it represents faces\n",
    "# if we reinitialze the ensemble for each input, then the curves\n",
    "# are meaningless \n",
    "def Model(X, numNeu, d, E,synap, T, isPlot):\n",
    "    lenX = len(X)\n",
    "    populationCurves = []\n",
    "    representations = []\n",
    "    sts = []\n",
    "    model = nengo.Network(seed=581)\n",
    "    with model:\n",
    "        ensA = nengo.Ensemble(n_neurons=numNeu,dimensions=d,encoders=E.T,normalize_encoders=False)\n",
    "    for i in range(len(X)):\n",
    "        with model:\n",
    "            inp = nengo.Node(X[i])\n",
    "            il = nengo.Connection(inp,ensA.neurons)\n",
    "            inpProbe = nengo.Probe(inp)\n",
    "            spikes = nengo.Probe(ensA.neurons)\n",
    "            voltage = nengo.Probe(ensA.neurons, 'voltage')\n",
    "            filtered = nengo.Probe(ensA,synapse=synap)\n",
    "        with nengo.Simulator(model, progress_bar=False, optimize=True) as sim:\n",
    "            if i%10==0: print(\"running simulation for step:\",i)\n",
    "            sim.run(T)\n",
    "            # x_axis = 50 x vals\n",
    "            # y_axis = n_neurons * 50 y values\n",
    "            responseCurves = response_curves(ensA,sim)\n",
    "            populationCurves.append(responseCurves)\n",
    "            representations.append(responseCurves[1])\n",
    "            sts.append(sim.data[filtered].T)\n",
    "            if isPlot:\n",
    "                plt.subplot(12,7,i+1)\n",
    "                plt.plot(sim.trange(), sim.data[filtered])\n",
    "    plt.show()\n",
    "    return populationCurves, representations, sts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotImages(X):\n",
    "    NN = int(np.floor(np.sqrt(len(X))))\n",
    "    fig,axs = plt.subplots(NN,NN,figsize=(5.5,7))\n",
    "    for i in range(NN):\n",
    "        for j in range(NN):\n",
    "            axs[i,j].imshow(X[NN*i+j].reshape(h,w),cmap='gray')\n",
    "            axs[i,j].set_xticks([])\n",
    "            axs[i, j].set_yticks([])\n",
    "    fig.tight_layout(w_pad=0.0,h_pad=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeroHorizontal(X,s,e):\n",
    "    for x in X:\n",
    "        for i in range(s,e):\n",
    "            x[i] = -1\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First get neural response for origianl face data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "curves1,reps1,st1 = Model(X=X,numNeu=h*w,d=15,E=encoders,synap=0.01,T=5,isPlot=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: subtract mean face"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run this experiment to see if the neural response of our population will have less overlap, if the original inputs have less overlap. And depending on which output signals are better, we will use them to compare to the rest of our experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "meanFace = np.mean(X,axis=0)\n",
    "X1 = [x-meanFace for x in X]\n",
    "plotImages(np.array(X).reshape(N,h,w))\n",
    "plotImages(np.array(X1).reshape(N,h,w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "curvesX1,repsX1,stX1 = Model(X=X1,numNeu=h*w,d=15,E=encoders,synap=0.01,T=5,isPlot=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: drastically darkening skin colour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will perform the following by deconstructing each face's PCA weights, and increasing the weight that corresponds to PC2, and reconstructing the face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get weights [w1,w2,...,wn] where n is 2700, by computing [PCi * (Xi - meanFace)] for i in range(1,n)\n",
    "# note we use all n weights to reconstruct the image after amplifying PC2, because we do not want to\n",
    "# reduce image quality here, we just want to adjust a certain component of the image.\n",
    "def getWeights(X, PCs, meanFace):\n",
    "    weights = []\n",
    "    for i in range(len(X)):\n",
    "        w = PCs[i] * (X[i] - meanFace)\n",
    "        weights.append(w)\n",
    "    return weights\n",
    "\n",
    "# i is the ith component we would like to darken\n",
    "def darkenComponent(i,weights,factor):\n",
    "    for w in weights:\n",
    "        w[i] *= -factor if w[i]>0 else factor\n",
    "        if w[i] < -1: w[i] = -1\n",
    "            \n",
    "def reconstructFaces(weights,PCs):\n",
    "    faces = []\n",
    "    for ws in weights:\n",
    "        face = np.zeros(len(ws))\n",
    "        for w,pc in zip(ws,PCs):\n",
    "            face += w*pc\n",
    "        faces.append(face)\n",
    "    return faces\n",
    "#weights = getWeights(X,V,meanFace)\n",
    "#darkenComponent(1, weights, 1)\n",
    "#X2 = reconstructFaces(weights,V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ^ above reconstruction method did not work so we will just add more of a component to all our faces.\n",
    "def changeComponent(change,i, PCs, originalFaces, factor):\n",
    "    newFaces = []\n",
    "    for f in originalFaces.reshape(N,h*w):\n",
    "        newFace = f - factor*PCs[i] if change==\"darken\" else f +factor*PCs[i]\n",
    "        newFaces.append(newFace)\n",
    "    return newFaces\n",
    "X2 = changeComponent(\"darken\",0,V,X,15)\n",
    "plotImages(np.array(X2).reshape(N,h,w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curvesX2,repsX2,stX2 = Model(X=X2,numNeu=h*w,d=15,E=encoders,synap=0.01,T=5,isPlot=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X12 = changeComponent(\"darken\",0,V,np.array(X1),10)\n",
    "plotImages(np.array(X12).reshape(N,h,w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curvesX12,repsX12,stX12 = Model(X=X12,numNeu=h*w,d=15,E=encoders,synap=0.01,T=5,isPlot=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3: drastically brighten skin colour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3 = changeComponent(\"brighten\",0,V,X,15)\n",
    "plotImages(np.array(X3).reshape(N,h,w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curvesX3,repsX3,stX3 = Model(X=X3,numNeu=h*w,d=15,E=encoders,synap=0.01,T=5,isPlot=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X13 = changeComponent(\"brighten\",0,V,np.array(X1),15)\n",
    "plotImages(np.array(X13).reshape(N,h,w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curvesX13,repsX13,stX13 = Model(X=X13,numNeu=h*w,d=15,E=encoders,synap=0.01,T=5,isPlot=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
